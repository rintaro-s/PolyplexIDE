import express from 'express'
import cors from 'cors'
import dotenv from 'dotenv'
import fs from 'fs'
import path from 'path'
import { fileURLToPath } from 'url'

dotenv.config()

const __dirname = path.dirname(fileURLToPath(import.meta.url))
const app = express()
app.use(cors())
app.use(express.json({ limit: '20mb' }))

const DB_PATH = path.join(__dirname, 'db.json')

// â”€â”€â”€ 5D Git Quality Gates â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const Y_COMMIT_THRESHOLD    = 95   // overall score required for pending_approval
const Y_MIN_FILE_SCORE      = 85   // per-file minimum
const Y_MIN_Z_DEPTH         = 3    // must survive at least 3 refinement rounds
const MAX_Z_DEPTH           = 5    // max iterations before giving up
const AUTO_APPROVE_DEFAULT  = 98   // score required for auto-commit

// â”€â”€â”€ Agent Role Definitions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Each agent: strict system prompt + conservative temperature
const AGENTS = {
  architect: {
    temperature: 0.25,
    system: `You are a world-class software architect with 20+ years shipping production systems.
Given a product requirement, output a complete architecture specification as JSON.

You are designing for PRODUCTION â€” real auth, real DB, real error handling.
No "TODO later" architecture. Every design decision must be justified.

Output ONLY valid JSON (no markdown fences, no explanation text):
{
  "projectName": "snake_case",
  "description": "2â€“3 sentences",
  "techStack": {
    "runtime": "...",
    "framework": "...",
    "database": "...",
    "auth": "...",
    "testing": "...",
    "other": []
  },
  "architecture": "paragraph describing system design",
  "dataModels": [
    { "name": "User", "fields": { "id": "uuid", "email": "string" }, "relations": ["has many Posts"] }
  ],
  "apiEndpoints": [
    { "method": "POST", "path": "/api/auth/login", "auth": false, "description": "..." }
  ],
  "files": [
    {
      "path": "src/server/routes/auth.ts",
      "purpose": "JWT auth endpoints: login, register, refresh, logout",
      "exports": ["authRouter"],
      "dependencies": ["src/server/db/users.ts", "src/lib/jwt.ts"],
      "priority": 1
    }
  ],
  "environmentVars": ["DATABASE_URL", "JWT_SECRET"],
  "implementationNotes": "critical decisions engineers must know"
}

Keep files â‰¤ 12. Priority 1 = implement first.`,
  },

  engineer: {
    temperature: 0.35,
    system: `You are a senior engineer writing production-ready code.

ABSOLUTE RULES â€” violating any = failure:
1. COMPLETE code only. Zero TODOs, zero "add logic here", zero placeholder functions.
2. Full error handling on every async operation, DB call, external API call.
3. Input validation on every public function/endpoint.
4. Real business logic â€” if it's auth, implement real JWT. If it's DB, write real queries.
5. Type-safe throughout (TypeScript: no implicit 'any').
6. Self-contained: all imports resolved from the file's declared dependencies.
7. If the file is a UI component: handle loading, error, and empty states.

Output the raw source code ONLY â€” no markdown, no comments outside the code, no explanation.`,
  },

  critic: {
    temperature: 0.15,
    system: `You are an adversarial code reviewer whose job is to find every problem.

Scoring guide:
- 95â€“100: Ship today, zero changes needed
- 85â€“94: Production-ready with minor improvements
- 70â€“84: Significant issues, not ready to ship
- 50â€“69: Substantial problems requiring rewrite of sections
- 0â€“49: Fundamentally broken or incomplete

Review for ALL of:
1. Correctness â€” does the code actually implement the stated purpose?
2. Completeness â€” any TODO, placeholder, unimplemented function?
3. Error handling â€” every throw-able path caught and handled?
4. Security â€” SQLi, XSS, auth bypass, exposed secrets, IDOR?
5. Edge cases â€” null/undefined, empty arrays, concurrent access?
6. Type safety â€” unsafe casts, missing null checks?
7. Performance â€” N+1 queries, unindexed reads, memory leaks?
8. Integration â€” imports match declared dependencies?

Output ONLY valid JSON:
{
  "score": 0-100,
  "summary": "one sentence",
  "critical": ["blocking bug: description"],
  "major": ["significant issue: description"],
  "minor": ["suggestion: description"],
  "security": ["vulnerability: description"],
  "missing": ["feature/case not implemented"]
}`,
  },

  refiner: {
    temperature: 0.3,
    system: `You are an expert code refiner. You receive buggy/incomplete code + a detailed critique.

Fix EVERY critical issue. Fix EVERY major issue. Address as many minor issues as feasible.
Do not break existing functionality. Maintain the same file path and exports.
Do not downgrade: the refined code must be strictly better than the original.

Output the complete, improved source code ONLY â€” no markdown, no explanation.`,
  },

  integrator: {
    temperature: 0.15,
    system: `You are a systems integrator verifying that multiple files work together.

Check:
1. Import paths â€” every import/require resolves to a real file in the project
2. Interface contracts â€” exported types match how they're consumed
3. Data shapes â€” function return values match callers' expectations
4. Environment â€” all env vars referenced actually defined in architecture
5. Auth flow â€” auth middleware applied consistently where required
6. DB schema â€” every DB access matches the defined data models
7. Circular imports â€” any problematic cycles?

Output ONLY valid JSON:
{
  "overallScore": 0-100,
  "compatible": true|false,
  "issues": [{ "file": "a.ts", "other": "b.ts", "problem": "..." }],
  "missing": ["glue code or connections that need to be added"],
  "envVars": ["vars referenced but not in architecture"],
  "summary": "1â€“2 sentence verdict"
}`,
  },
}

// â”€â”€â”€ DB Helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
function defaultSettings() {
  return {
    defaultProvider: process.env.DEFAULT_PROVIDER || 'openai',
    defaultModel: '',
    autoApprove: false,
    autoApproveThreshold: AUTO_APPROVE_DEFAULT,
  }
}

function ensureDefaults(db) {
  db.tasks      = Array.isArray(db.tasks)     ? db.tasks     : []
  db.stream     = Array.isArray(db.stream)    ? db.stream    : []
  db.wisdomLog  = Array.isArray(db.wisdomLog) ? db.wisdomLog : []
  db.settings   = db.settings || defaultSettings()
  return db
}

function readDB() {
  if (!fs.existsSync(DB_PATH)) {
    const db = ensureDefaults({})
    fs.writeFileSync(DB_PATH, JSON.stringify(db, null, 2))
    return db
  }
  try { return ensureDefaults(JSON.parse(fs.readFileSync(DB_PATH, 'utf-8'))) }
  catch { return ensureDefaults({}) }
}

function writeDB(data) {
  fs.writeFileSync(DB_PATH, JSON.stringify(ensureDefaults(data), null, 2))
}

function saveTask(taskId, updater) {
  const db = readDB()
  const idx = db.tasks.findIndex(t => t.id === taskId)
  if (idx !== -1) { updater(db.tasks[idx]); writeDB(db) }
}

// â”€â”€â”€ LLM Call â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async function callLLM(provider, model, messages, temperature) {
  const { default: fetch } = await import('node-fetch').catch(() => ({ default: globalThis.fetch }))

  if (provider === 'openai' || provider === 'lmstudio') {
    const baseURL = provider === 'lmstudio'
      ? (process.env.LMSTUDIO_URL || 'http://localhost:1234') + '/v1'
      : 'https://api.openai.com/v1'
    const apiKey = provider === 'lmstudio' ? 'lm-studio' : (process.env.OPENAI_API_KEY || '')
    const resp = await fetch(`${baseURL}/chat/completions`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json', Authorization: `Bearer ${apiKey}` },
      body: JSON.stringify({
        model: model || (provider === 'lmstudio' ? 'local-model' : 'gpt-4o'),
        messages,
        temperature: temperature ?? 0.5,
      }),
    })
    if (!resp.ok) throw new Error(`${provider} error ${resp.status}: ${await resp.text()}`)
    return (await resp.json()).choices[0].message.content
  }

  if (provider === 'gemini') {
    const apiKey = process.env.GEMINI_API_KEY || ''
    const gemModel = model || 'gemini-2.0-flash'
    const resp = await fetch(
      `https://generativelanguage.googleapis.com/v1beta/models/${gemModel}:generateContent?key=${apiKey}`,
      {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          contents: messages.map(m => ({
            role: m.role === 'assistant' ? 'model' : 'user',
            parts: [{ text: m.content }],
          })),
          generationConfig: { temperature: temperature ?? 0.5 },
        }),
      }
    )
    if (!resp.ok) throw new Error(`Gemini error ${resp.status}: ${await resp.text()}`)
    return (await resp.json()).candidates[0].content.parts[0].text
  }

  throw new Error(`Unknown provider: ${provider}`)
}

async function runAgent(role, userMsg, provider, model) {
  const agent = AGENTS[role]
  if (!agent) throw new Error(`No agent: ${role}`)
  return callLLM(provider, model, [
    { role: 'system', content: agent.system },
    { role: 'user',   content: userMsg },
  ], agent.temperature)
}

function parseJSON(text) {
  if (!text) return null
  const s = text.replace(/^```(?:json)?\s*/m, '').replace(/\s*```\s*$/m, '').trim()
  try { return JSON.parse(s) } catch { return null }
}

function ts() { return new Date().toISOString().slice(11, 19) }

// â”€â”€â”€ Core 5D Git Workflow â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async function runDeepWorkflow(taskId) {
  // read the latest DB state and find the task
  let db   = readDB()
  let task = db.tasks.find(t => t.id === taskId)
  if (!task) return

  const { provider, model, prompt } = task
  const wisdom = (db.wisdomLog || []).slice(-12)
  const wisdomCtx = wisdom.length
    ? '\n\nLessons learned from past projects:\n' + wisdom.map(w => `- ${w}`).join('\n')
    : ''

  const log = (msg) => {
    saveTask(taskId, t => { t.thinkingLog.push(`[${ts()}] ${msg}`) })
  }

  try {
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // X AXIS â€” Architect produces the branch specification
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    log('ðŸ“ [Architect] è¦ä»¶åˆ†æžãƒ»ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã‚’é–‹å§‹...')

    const archRaw = await runAgent('architect',
      `Requirement:\n${prompt}${wisdomCtx}`,
      provider, model
    )
    const arch = parseJSON(archRaw)
    if (!arch?.files?.length) throw new Error('Architect returned invalid JSON or empty file list')

    saveTask(taskId, t => {
      t.architecture = arch
      t.files        = []
    })
    log(`ðŸ“ [Architect] å®Œäº† â€” ${arch.files.length}ãƒ•ã‚¡ã‚¤ãƒ« / stack: ${Object.values(arch.techStack || {}).filter(Boolean).slice(0, 3).join(', ')}`)
    log(`ðŸ“ [Architect] è¨­è¨ˆ: ${arch.architecture}`)

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // Z AXIS DEPTH 1 â€” Engineer implements every file
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    saveTask(taskId, t => { t.zDepth = 1 })
    log(`âš™ï¸  [Engineer] Z=1: ${arch.files.length}ãƒ•ã‚¡ã‚¤ãƒ«ã®å®Œå…¨å®Ÿè£…é–‹å§‹...`)

    const sortedFiles = [...arch.files]
      .sort((a, b) => (a.priority || 5) - (b.priority || 5))
      .slice(0, 12)  // max 12 files per task

    for (const spec of sortedFiles) {
      log(`âš™ï¸  [Engineer] å®Ÿè£…: ${spec.path}`)

      const implPrompt = [
        `Project: ${arch.projectName}`,
        `Overall architecture: ${arch.architecture}`,
        `Tech stack: ${JSON.stringify(arch.techStack)}`,
        `Data models: ${JSON.stringify(arch.dataModels || [])}`,
        `API endpoints: ${JSON.stringify(arch.apiEndpoints || [])}`,
        `Implementation notes: ${arch.implementationNotes || 'none'}`,
        `Environment vars available: ${(arch.environmentVars || []).join(', ')}`,
        ``,
        `FILE TO IMPLEMENT`,
        `Path: ${spec.path}`,
        `Purpose: ${spec.purpose}`,
        `Exports: ${(spec.exports || []).join(', ')}`,
        `Depends on: ${(spec.dependencies || []).join(', ')}`,
        ``,
        `Original requirement: ${prompt}`,
      ].join('\n')

      let code = `// SKIPPED: generation not attempted`
      try {
        code = await runAgent('engineer', implPrompt, provider, model)
      } catch (err) {
        code = `// GENERATION ERROR for ${spec.path}\n// ${err.message}`
        log(`âš™ï¸  [Engineer] ERROR ${spec.path}: ${err.message}`)
      }

      saveTask(taskId, t => {
        t.files.push({
          path:      spec.path,
          purpose:   spec.purpose,
          code,
          score:     null,
          critique:  null,
          zDepth:    1,
          refined:   false,
        })
      })
    }

    db   = readDB()
    task = db.tasks.find(t => t.id === taskId)
    log(`âš™ï¸  [Engineer] Z=1å®Œäº† â€” ${task.files.length}ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆæ¸ˆã¿`)

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // Z AXIS REFINEMENT LOOP â€” critic â†’ refine until quality
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    async function criticPass(zLabel) {
      log(`ðŸ” [Critic] Z=${zLabel}: å…¨${task.files.length}ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åŽ³æ ¼ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¸­...`)

      for (const file of task.files) {
        if (!file.code || file.code.startsWith('// GENERATION ERROR') || file.code.startsWith('// SKIPPED')) {
          file.score    = 0
          file.critique = { score: 0, summary: 'Generation failed', critical: ['Code was not generated'], major: [], minor: [], security: [], missing: [] }
          continue
        }

        const criticPrompt = [
          `Requirement: ${prompt}`,
          `Architecture: ${arch.architecture}`,
          `File: ${file.path}  (Purpose: ${file.purpose})`,
          ``,
          `--- CODE ---`,
          file.code,
        ].join('\n')

        try {
          const raw      = await runAgent('critic', criticPrompt, provider, model)
          const critique = parseJSON(raw)
          file.critique  = critique
          file.score     = critique?.score ?? 40
          const crit = critique?.critical?.length ?? 0
          const maj  = critique?.major?.length ?? 0
          log(`ðŸ” [Critic] ${file.path} â†’ ${file.score}ç‚¹ (critical:${crit} major:${maj})`)
        } catch (err) {
          file.score    = 30
          file.critique = { score: 30, summary: 'Review error', critical: [err.message], major: [], minor: [], security: [], missing: [] }
          log(`ðŸ” [Critic] ERROR ${file.path}: ${err.message}`)
        }

        saveTask(taskId, t => {
          const f = t.files.find(x => x.path === file.path)
          if (f) { f.score = file.score; f.critique = file.critique }
        })
      }

      const scores  = task.files.map(f => f.score ?? 0)
      const avg     = scores.reduce((a, b) => a + b, 0) / (scores.length || 1)
      const min     = Math.min(...scores)
      log(`ðŸ” [Critic] Z=${zLabel}ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº† â€” å¹³å‡${avg.toFixed(1)}ç‚¹ / æœ€ä½Ž${min}ç‚¹`)
      return { avg, min }
    }

    async function refinePass(zDepth) {
      const toRefine = task.files.filter(f => (f.score ?? 100) < 90)
      if (toRefine.length === 0) {
        log(`âœ¨ [Refiner] Z=${zDepth}: å…¨ãƒ•ã‚¡ã‚¤ãƒ«åŸºæº–ã‚¯ãƒªã‚¢ â€” ã‚¹ã‚­ãƒƒãƒ—`)
        return
      }
      log(`âœ¨ [Refiner] Z=${zDepth}: ${toRefine.length}ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ”¹å–„ä¸­...`)

      for (const file of toRefine) {
        if (!file.critique) continue

        const refinePrompt = [
          `Requirements: ${prompt}`,
          `Architecture: ${arch.architecture}`,
          `File: ${file.path}  (Purpose: ${file.purpose})`,
          ``,
          `--- ORIGINAL CODE ---`,
          file.code,
          ``,
          `--- CRITIC REVIEW (score: ${file.score}) ---`,
          JSON.stringify(file.critique, null, 2),
          ``,
          `Fix all critical and major issues. Rewrite sections as needed.`,
        ].join('\n')

        try {
          const refined = await runAgent('refiner', refinePrompt, provider, model)
          file.code    = refined
          file.refined = true
          file.zDepth  = zDepth
          log(`âœ¨ [Refiner] ${file.path} æ”¹å–„å®Œäº†`)
        } catch (err) {
          log(`âœ¨ [Refiner] ERROR ${file.path}: ${err.message}`)
        }

        saveTask(taskId, t => {
          const f = t.files.find(x => x.path === file.path)
          if (f) { f.code = file.code; f.zDepth = file.zDepth; f.refined = file.refined }
        })
      }
    }

    // Force at least 3 rounds (Y_MIN_Z_DEPTH)
    let avgScore, minScore
    const firstCritic = await criticPass(1)
    avgScore = firstCritic.avg
    minScore = firstCritic.min

    for (let z = 2; z <= MAX_Z_DEPTH; z++) {
      // Refine any files below threshold
      await refinePass(z)
      // Re-critique
      const r = await criticPass(z)
      avgScore = r.avg
      minScore = r.min
      saveTask(taskId, t => { t.zDepth = z })
      task = readDB().tasks.find(t => t.id === taskId) || task

      // Stop early only if: min Z depth met AND quality sufficient
      if (z >= Y_MIN_Z_DEPTH && avgScore >= Y_COMMIT_THRESHOLD && minScore >= Y_MIN_FILE_SCORE) {
        log(`ðŸŽ¯ Z=${z}: å“è³ªåŸºæº–ã‚¯ãƒªã‚¢ â€” ãƒ«ãƒ¼ãƒ—çµ‚äº†`)
        break
      }
      if (z >= Y_MIN_Z_DEPTH && z >= MAX_Z_DEPTH) {
        log(`âš ï¸  Z=${z}: æœ€å¤§æ·±åº¦åˆ°é”`)
        break
      }
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // INTEGRATOR â€” cross-file consistency check
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    log(`ðŸ”— [Integrator] ãƒ•ã‚¡ã‚¤ãƒ«é–“æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ä¸­...`)

    const fileSummaries = task.files.map(f => ({
      path:    f.path,
      purpose: f.purpose,
      snippet: f.code?.slice(0, 600) ?? '',
    }))

    let integration = null
    try {
      const intRaw  = await runAgent('integrator',
        `Architecture:\n${JSON.stringify(arch, null, 2)}\n\nFiles:\n${JSON.stringify(fileSummaries, null, 2)}`,
        provider, model
      )
      integration = parseJSON(intRaw)
      const is = integration?.overallScore ?? 70
      log(`ðŸ”— [Integrator] ã‚¹ã‚³ã‚¢: ${is}% â€” ${integration?.summary ?? ''}`)
      if (integration?.issues?.length) {
        integration.issues.slice(0, 3).forEach(i => log(`ðŸ”— [Integrator] âš   ${i.file} Ã— ${i.other || ''}: ${i.problem}`))
      }
    } catch (err) {
      log(`ðŸ”— [Integrator] ERROR: ${err.message}`)
    }

    saveTask(taskId, t => { t.integration = integration })

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // FINAL SCORE & STATUS
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    const integBonus   = integration?.compatible ? 2 : integration ? -5 : 0
    const fileScores   = task.files.map(f => f.score ?? 0)
    const finalAvg     = fileScores.reduce((a, b) => a + b, 0) / (fileScores.length || 1)
    const finalMin     = Math.min(...fileScores)
    const finalScore   = Math.min(100, Math.round(finalAvg + integBonus))

    db   = readDB()
    task = db.tasks.find(t => t.id === taskId)
    if (!task) return

    task.score = finalScore
    task.diff  = [
      `Zæ·±åº¦: ${task.zDepth}`,
      `ãƒ•ã‚¡ã‚¤ãƒ«: ${task.files.length}`,
      `å¹³å‡ã‚¹ã‚³ã‚¢: ${finalAvg.toFixed(1)}%`,
      `æœ€ä½Žã‚¹ã‚³ã‚¢: ${finalMin}%`,
      `æ•´åˆæ€§: ${integration?.overallScore ?? '?'}%`,
    ].join(' / ')

    const yEligible = task.zDepth >= Y_MIN_Z_DEPTH
      && finalScore    >= Y_COMMIT_THRESHOLD
      && finalMin      >= Y_MIN_FILE_SCORE

    if (yEligible) {
      task.status = 'pending_approval'
      task.thinkingLog.push(`[${ts()}] âœ… Yè»¸ã‚³ãƒŸãƒƒãƒˆå¾…æ©Ÿ â€” ã‚¹ã‚³ã‚¢${finalScore}% Z=${task.zDepth} ãƒ•ã‚¡ã‚¤ãƒ«${task.files.length}å€‹`)
    } else {
      task.status = 'needs_work'
      const why = []
      if (task.zDepth  < Y_MIN_Z_DEPTH)       why.push(`Zæ·±åº¦${task.zDepth} (å¿…è¦:${Y_MIN_Z_DEPTH})`)
      if (finalScore   < Y_COMMIT_THRESHOLD)   why.push(`ç·åˆ${finalScore}% (å¿…è¦:${Y_COMMIT_THRESHOLD}%)`)
      if (finalMin     < Y_MIN_FILE_SCORE)     why.push(`æœ€ä½Žãƒ•ã‚¡ã‚¤ãƒ«${finalMin}% (å¿…è¦:${Y_MIN_FILE_SCORE}%)`)
      task.thinkingLog.push(`[${ts()}] âš ï¸  Yè»¸åŸºæº–æœªé”: ${why.join(', ')}`)
    }

    writeDB(db)

    // Auto-approve check
    const freshDB   = readDB()
    const freshTask = freshDB.tasks.find(t => t.id === taskId)
    if (freshTask?.status === 'pending_approval' && freshDB.settings.autoApprove) {
      const thresh = freshDB.settings.autoApproveThreshold ?? AUTO_APPROVE_DEFAULT
      if (finalScore >= thresh) {
        freshTask.thinkingLog.push(`[${ts()}] ðŸ¤– è‡ªå‹•Yè»¸ã‚³ãƒŸãƒƒãƒˆ â€” ã‚¹ã‚³ã‚¢${finalScore}% >= ${thresh}%`)
        commitToY(freshDB, freshTask, 'auto')
        writeDB(freshDB)
      }
    }

  } catch (err) {
    saveTask(taskId, t => {
      t.status = 'error'
      t.thinkingLog.push(`[${ts()}] âŒ ${err.message}`)
    })
    console.error(`[task ${taskId}] Workflow error:`, err)
  }
}

// â”€â”€â”€ Y-Axis Commit â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
function commitToY(db, task, reason = 'manual') {
  task.status     = 'approved'
  task.approvedAt = new Date().toISOString()

  const fileScores = (task.files || []).map(f => f.score ?? 0)
  const avgScore   = fileScores.length ? fileScores.reduce((a, b) => a + b, 0) / fileScores.length : 0

  db.stream.unshift({
    id:           task.id,
    title:        task.prompt,
    projectName:  task.architecture?.projectName ?? '',
    description:  task.architecture?.description ?? '',
    techStack:    task.architecture?.techStack    ?? {},
    score:        task.score,
    zDepth:       task.zDepth,
    fileCount:    (task.files || []).length,
    files:        task.files,
    architecture: task.architecture,
    integration:  task.integration,
    provider:     task.provider,
    approvedAt:   task.approvedAt,
    reason,
  })

  // W-axis: record wisdom from this project
  const stackStr = Object.values(task.architecture?.techStack || {}).filter(Boolean).join('/')
  db.wisdomLog.push(
    `Approved project "${task.prompt.slice(0, 70)}" â€” ` +
    `${task.files?.length ?? 0} files, stack: ${stackStr}, ` +
    `Z=${task.zDepth}, avg score: ${avgScore.toFixed(0)}%`
  )
}

// â”€â”€â”€ Create Task â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
function createTask(db, payload) {
  const settings = db.settings || defaultSettings()
  const taskId   = `task-${Date.now()}-${Math.floor(Math.random() * 9999)}`
  const task = {
    id:             taskId,
    prompt:         payload.prompt,
    originalPrompt: payload.originalPrompt ?? payload.prompt,
    provider:       payload.provider ?? settings.defaultProvider ?? 'openai',
    model:          payload.model    ?? settings.defaultModel    ?? null,
    status:         'running',
    // 5D axes
    xBranch:    payload.xBranch ?? 'main',
    yVersion:   db.stream.length,
    zDepth:     0,
    wConstraints: (db.wisdomLog || []).slice(-10),
    // content
    architecture: null,
    files:        [],
    integration:  null,
    // scores
    score:        null,
    diff:         null,
    // logs
    thinkingLog:  [],
    createdAt:    new Date().toISOString(),
    approvedAt:   null,
    parentId:     payload.parentId ?? null,
    source:       payload.source   ?? 'manual',
    feedback:     null,
  }
  db.tasks.push(task)
  writeDB(db)
  return taskId
}

// â”€â”€â”€ Routes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

app.get('/api/state', (_req, res) => {
  const db = readDB()
  res.json({ tasks: db.tasks, stream: db.stream, wisdomLog: db.wisdomLog })
})

app.get('/api/settings', (_req, res) => {
  res.json(readDB().settings)
})

app.post('/api/settings', (req, res) => {
  const db = readDB()
  db.settings = { ...db.settings, ...req.body }
  writeDB(db)
  res.json(db.settings)
})

app.get('/api/providers', (_req, res) => {
  res.json({
    openai:          !!process.env.OPENAI_API_KEY,
    gemini:          !!process.env.GEMINI_API_KEY,
    lmstudio:        true,
    defaultProvider: process.env.DEFAULT_PROVIDER || 'openai',
    lmstudioUrl:     process.env.LMSTUDIO_URL || 'http://localhost:1234',
  })
})

app.post('/api/providers', (req, res) => {
  const { openaiKey, geminiKey, lmstudioUrl, defaultProvider } = req.body
  const envPath = path.join(__dirname, '..', '.env')
  let lines = fs.existsSync(envPath) ? fs.readFileSync(envPath, 'utf-8').split('\n') : []
  const set = (k, v) => {
    const i = lines.findIndex(l => l.startsWith(k + '='))
    if (i >= 0) lines[i] = `${k}=${v}`; else lines.push(`${k}=${v}`)
  }
  if (openaiKey       != null) set('OPENAI_API_KEY',    openaiKey)
  if (geminiKey       != null) set('GEMINI_API_KEY',    geminiKey)
  if (lmstudioUrl     != null) set('LMSTUDIO_URL',      lmstudioUrl)
  if (defaultProvider != null) set('DEFAULT_PROVIDER',  defaultProvider)
  fs.writeFileSync(envPath, lines.filter(Boolean).join('\n') + '\n')
  dotenv.config({ override: true })
  res.json({ ok: true })
})

// Submit a new prompt â†’ creates task + spawns deep workflow
app.post('/api/prompt', async (req, res) => {
  const { prompt, provider, model } = req.body
  if (!prompt?.trim()) return res.status(400).json({ error: 'prompt required' })

  const db     = readDB()
  const taskId = createTask(db, { prompt: prompt.trim(), provider, model })
  res.json({ taskId })

  // Run async â€” do NOT await
  runDeepWorkflow(taskId).catch(err => console.error(`[${taskId}] fatal:`, err))
})

app.get('/api/tasks/:id', (req, res) => {
  const task = readDB().tasks.find(t => t.id === req.params.id)
  if (!task) return res.status(404).json({ error: 'not found' })
  res.json(task)
})

// Manual Y-axis commit (approve)
app.post('/api/tasks/:id/approve', (req, res) => {
  const db   = readDB()
  const task = db.tasks.find(t => t.id === req.params.id)
  if (!task) return res.status(404).json({ error: 'not found' })
  if (!['pending_approval', 'needs_work', 'error'].includes(task.status)) {
    return res.status(400).json({ error: `Cannot approve task in state: ${task.status}` })
  }
  commitToY(db, task, 'manual')
  writeDB(db)
  res.json({ ok: true })
})

// Reject + retry with W-axis feedback
app.post('/api/tasks/:id/reject', async (req, res) => {
  const db   = readDB()
  const task = db.tasks.find(t => t.id === req.params.id)
  if (!task) return res.status(404).json({ error: 'not found' })

  const { feedback = '' } = req.body || {}
  task.status   = 'rejected'
  task.feedback = feedback

  if (feedback.trim()) db.wisdomLog.push(feedback.trim())

  const newId = createTask(db, {
    prompt:         task.originalPrompt ?? task.prompt,
    originalPrompt: task.originalPrompt ?? task.prompt,
    provider:       task.provider,
    model:          task.model,
    parentId:       task.id,
    source:         'reject-retry',
  })

  const db2     = readDB()
  const newTask = db2.tasks.find(t => t.id === newId)
  if (newTask && feedback.trim()) {
    newTask.thinkingLog.push(
      `[${ts()}] Wè»¸: ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åæ˜  â€” "${feedback.trim()}"`
    )
    writeDB(db2)
  }

  res.json({ ok: true, newTaskId: newId })
  runDeepWorkflow(newId).catch(err => console.error(`[${newId}] retry fatal:`, err))
})

app.delete('/api/tasks/:id', (req, res) => {
  const db  = readDB()
  db.tasks  = db.tasks.filter(t => t.id !== req.params.id)
  writeDB(db)
  res.json({ ok: true })
})

app.delete('/api/stream/:id', (req, res) => {
  const db  = readDB()
  db.stream = db.stream.filter(s => s.id !== req.params.id)
  writeDB(db)
  res.json({ ok: true })
})

// Clear all
app.post('/api/reset', (_req, res) => {
  const db   = readDB()
  db.tasks   = []
  db.stream  = []
  writeDB(db)
  res.json({ ok: true })
})

const PORT = process.env.PORT || 3001
app.listen(PORT, () => {
  console.log(`Polyplex IDE backend â€” http://localhost:${PORT}`)
  console.log(`Y_COMMIT_THRESHOLD: ${Y_COMMIT_THRESHOLD}%  MIN_Z: ${Y_MIN_Z_DEPTH}  MAX_Z: ${MAX_Z_DEPTH}`)
})
